{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbced67-076c-474d-a9f6-a49f465c417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found: ['C:\\\\Users\\\\Admin\\\\Desktop\\\\bigdata\\\\yellow_tripdata_2025-01.parquet', 'C:\\\\Users\\\\Admin\\\\Desktop\\\\bigdata\\\\yellow_tripdata_2025-02.parquet', 'C:\\\\Users\\\\Admin\\\\Desktop\\\\bigdata\\\\yellow_tripdata_2025-04.parquet', 'C:\\\\Users\\\\Admin\\\\Desktop\\\\bigdata\\\\yellow_tripdata_2025-05.parquet', 'C:\\\\Users\\\\Admin\\\\Desktop\\\\bigdata\\\\yellow_tripdata_2025-06.parquet', 'C:\\\\Users\\\\Admin\\\\Desktop\\\\bigdata\\\\yellow_tripdata_2025-07 (1).parquet', 'C:\\\\Users\\\\Admin\\\\Desktop\\\\bigdata\\\\yellow_tripdata_2025-08.parquet']\n",
      "Merged dataset shape: (27411181, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get all yellow taxi Parquet files in folder\n",
    "path = r\"C:\\Users\\Admin\\Desktop\\bigdata\\yellow_*.parquet\"\n",
    "all_files = glob.glob(path)\n",
    "\n",
    "print(\"Files found:\", all_files)\n",
    "\n",
    "# Read and merge\n",
    "df_list = [pd.read_parquet(f) for f in all_files]\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(\"Merged dataset shape:\", df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbb553d-f3ee-4d9e-8a8c-1a82415adb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "VendorID                       0\n",
      "tpep_pickup_datetime           0\n",
      "tpep_dropoff_datetime          0\n",
      "passenger_count          6426927\n",
      "trip_distance                  0\n",
      "RatecodeID               6426927\n",
      "store_and_fwd_flag       6426927\n",
      "PULocationID                   0\n",
      "DOLocationID                   0\n",
      "payment_type                   0\n",
      "fare_amount                    0\n",
      "extra                          0\n",
      "mta_tax                        0\n",
      "tip_amount                     0\n",
      "tolls_amount                   0\n",
      "improvement_surcharge          0\n",
      "total_amount                   0\n",
      "congestion_surcharge     6426927\n",
      "Airport_fee              6426927\n",
      "cbd_congestion_fee             0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of missing values per column:\n",
      "VendorID                  0.00000\n",
      "tpep_pickup_datetime      0.00000\n",
      "tpep_dropoff_datetime     0.00000\n",
      "passenger_count          23.44637\n",
      "trip_distance             0.00000\n",
      "RatecodeID               23.44637\n",
      "store_and_fwd_flag       23.44637\n",
      "PULocationID              0.00000\n",
      "DOLocationID              0.00000\n",
      "payment_type              0.00000\n",
      "fare_amount               0.00000\n",
      "extra                     0.00000\n",
      "mta_tax                   0.00000\n",
      "tip_amount                0.00000\n",
      "tolls_amount              0.00000\n",
      "improvement_surcharge     0.00000\n",
      "total_amount              0.00000\n",
      "congestion_surcharge     23.44637\n",
      "Airport_fee              23.44637\n",
      "cbd_congestion_fee        0.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_all is your merged dataset\n",
    "# Check missing values per column\n",
    "missing = df_all.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing)\n",
    "\n",
    "# Optional: percentage of missing values\n",
    "missing_percent = (df_all.isnull().sum() / len(df_all)) * 100\n",
    "print(\"\\nPercentage of missing values per column:\")\n",
    "print(missing_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9512501-e325-4580-b541-e51169b008b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID                 0\n",
      "tpep_pickup_datetime     0\n",
      "tpep_dropoff_datetime    0\n",
      "passenger_count          0\n",
      "trip_distance            0\n",
      "RatecodeID               0\n",
      "store_and_fwd_flag       0\n",
      "PULocationID             0\n",
      "DOLocationID             0\n",
      "payment_type             0\n",
      "fare_amount              0\n",
      "extra                    0\n",
      "mta_tax                  0\n",
      "tip_amount               0\n",
      "tolls_amount             0\n",
      "improvement_surcharge    0\n",
      "total_amount             0\n",
      "congestion_surcharge     0\n",
      "Airport_fee              0\n",
      "cbd_congestion_fee       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing passenger_count with median\n",
    "df_all['passenger_count'] = df_all['passenger_count'].fillna(df_all['passenger_count'].median())\n",
    "\n",
    "# Fill missing RatecodeID with most frequent value\n",
    "df_all['RatecodeID'] = df_all['RatecodeID'].fillna(df_all['RatecodeID'].mode()[0])\n",
    "\n",
    "# Fill missing store_and_fwd_flag with 'N' (most common)\n",
    "df_all['store_and_fwd_flag'] = df_all['store_and_fwd_flag'].fillna('N')\n",
    "\n",
    "# Fill congestion_surcharge and Airport_fee with 0\n",
    "df_all['congestion_surcharge'] = df_all['congestion_surcharge'].fillna(0)\n",
    "df_all['Airport_fee'] = df_all['Airport_fee'].fillna(0)\n",
    "\n",
    "# Verify again\n",
    "print(df_all.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc66d2c-c6df-477a-945d-fd30a0dca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Count number of occurrences of each trip\n",
    "trip_counts = df_all.groupby(['tpep_pickup_datetime', 'tpep_dropoff_datetime', \n",
    "                              'PULocationID', 'DOLocationID', 'trip_distance', 'fare_amount']).size()\n",
    "\n",
    "# Take only trips that occur more than once\n",
    "trip_duplicates = trip_counts[trip_counts > 1]\n",
    "\n",
    "# Plot top 20 duplicate trips\n",
    "trip_duplicates.sort_values(ascending=False).head(20).plot(kind='bar', figsize=(12,6))\n",
    "plt.title(\"Top 20 Duplicate Trips (Count > 1)\")\n",
    "plt.ylabel(\"Number of occurrences\")\n",
    "plt.xlabel(\"Trip (pickup & dropoff info)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1428bc-b056-4016-9238-9d2d6aa9e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total duplicate rows\n",
    "total_duplicates = df_all.duplicated().sum()\n",
    "print(\"Total duplicate rows:\", total_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3270cc04-6711-4203-a23a-2183532d1e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3a7ca-7834-4349-8388-c26e09233e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
